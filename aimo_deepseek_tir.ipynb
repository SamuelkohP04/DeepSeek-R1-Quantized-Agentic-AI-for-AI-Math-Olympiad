{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install smolagents ddgs --upgrade transformers nvidia-modelopt==0.19.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:20:16.373252Z","iopub.execute_input":"2026-01-11T09:20:16.373535Z","iopub.status.idle":"2026-01-11T09:20:20.360509Z","shell.execute_reply.started":"2026-01-11T09:20:16.373503Z","shell.execute_reply":"2026-01-11T09:20:20.359473Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: smolagents in /usr/local/lib/python3.12/dist-packages (1.23.0)\nRequirement already satisfied: ddgs in /usr/local/lib/python3.12/dist-packages (9.10.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\nRequirement already satisfied: nvidia-modelopt==0.19.0 in /usr/local/lib/python3.12/dist-packages (0.19.0)\nRequirement already satisfied: cloudpickle>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (3.1.1)\nRequirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (1.13.0)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (25.0)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (2.12.5)\nRequirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (14.2.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (1.15.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (4.67.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from nvidia-modelopt==0.19.0) (75.2.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.31.2 in /usr/local/lib/python3.12/dist-packages (from smolagents) (0.36.0)\nRequirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from smolagents) (2.32.5)\nRequirement already satisfied: jinja2>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from smolagents) (3.1.6)\nRequirement already satisfied: pillow>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from smolagents) (11.3.0)\nRequirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from smolagents) (1.1.1)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.1)\nRequirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\nRequirement already satisfied: lxml>=4.9.4 in /usr/local/lib/python3.12/dist-packages (from ddgs) (5.4.0)\nRequirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\nRequirement already satisfied: fake-useragent>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (2.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\nRequirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\nRequirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\nRequirement already satisfied: socksio==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.31.2->smolagents) (1.2.1rc0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.4->smolagents) (3.0.3)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->nvidia-modelopt==0.19.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->nvidia-modelopt==0.19.0) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->nvidia-modelopt==0.19.0) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (2.6.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->nvidia-modelopt==0.19.0) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->nvidia-modelopt==0.19.0) (2.19.2)\nRequirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\nRequirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->nvidia-modelopt==0.19.0) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip uninstall numpy pandas scipy scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:20:20.363287Z","iopub.execute_input":"2026-01-11T09:20:20.363907Z","iopub.status.idle":"2026-01-11T09:20:34.630345Z","shell.execute_reply.started":"2026-01-11T09:20:20.363873Z","shell.execute_reply":"2026-01-11T09:20:34.629701Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: numpy 1.26.4\nUninstalling numpy-1.26.4:\n  Would remove:\n    /usr/local/bin/f2py\n    /usr/local/lib/python3.12/dist-packages/numpy-1.26.4.dist-info/*\n    /usr/local/lib/python3.12/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n    /usr/local/lib/python3.12/dist-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so\n    /usr/local/lib/python3.12/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n    /usr/local/lib/python3.12/dist-packages/numpy/*\nProceed (Y/n)? ^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install numpy pandas scipy scikit-learn bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:21:19.849146Z","iopub.execute_input":"2026-01-11T09:21:19.849502Z","iopub.status.idle":"2026-01-11T09:21:25.155249Z","shell.execute_reply.started":"2026-01-11T09:21:19.849471Z","shell.execute_reply":"2026-01-11T09:21:25.154364Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.15.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.49.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom smolagents import TransformersModel, CodeAgent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:21:25.156929Z","iopub.execute_input":"2026-01-11T09:21:25.157258Z","iopub.status.idle":"2026-01-11T09:21:25.161256Z","shell.execute_reply.started":"2026-01-11T09:21:25.157228Z","shell.execute_reply":"2026-01-11T09:21:25.160628Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### 1. Configuration for 4-bit Quantization","metadata":{}},{"cell_type":"code","source":"# 1. Configuration for 4-bit quantization\nprint(\"--- Loading Model: DeepSeek-R1-Distill-Qwen-7B ---\")\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:21:25.373599Z","iopub.execute_input":"2026-01-11T09:21:25.373831Z","iopub.status.idle":"2026-01-11T09:21:25.386348Z","shell.execute_reply.started":"2026-01-11T09:21:25.373809Z","shell.execute_reply":"2026-01-11T09:21:25.385748Z"}},"outputs":[{"name":"stdout","text":"--- Loading Model: DeepSeek-R1-Distill-Qwen-7B ---\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"quantization_config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:21:27.496281Z","iopub.execute_input":"2026-01-11T09:21:27.497025Z","iopub.status.idle":"2026-01-11T09:21:27.502720Z","shell.execute_reply.started":"2026-01-11T09:21:27.496992Z","shell.execute_reply":"2026-01-11T09:21:27.502025Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"BitsAndBytesConfig {\n  \"_load_in_4bit\": true,\n  \"_load_in_8bit\": false,\n  \"bnb_4bit_compute_dtype\": \"float16\",\n  \"bnb_4bit_quant_storage\": \"uint8\",\n  \"bnb_4bit_quant_type\": \"nf4\",\n  \"bnb_4bit_use_double_quant\": true,\n  \"llm_int8_enable_fp32_cpu_offload\": false,\n  \"llm_int8_has_fp16_weight\": false,\n  \"llm_int8_skip_modules\": null,\n  \"llm_int8_threshold\": 6.0,\n  \"load_in_4bit\": true,\n  \"load_in_8bit\": false,\n  \"quant_method\": \"bitsandbytes\"\n}"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"### 2. Load the DeepSeek-R1 Distilled Model","metadata":{}},{"cell_type":"code","source":"model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n# model = AutoModelForCausalLM.from_pretrained(\n#     model_id,\n#     quantization_config=quantization_config,\n#     device_map=\"auto\", # Automatically puts layers on the GPU\n#     trust_remote_code=True\n# )\n# model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:21:29.059045Z","iopub.execute_input":"2026-01-11T09:21:29.059719Z","iopub.status.idle":"2026-01-11T09:21:30.687639Z","shell.execute_reply.started":"2026-01-11T09:21:29.059689Z","shell.execute_reply":"2026-01-11T09:21:30.686737Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d26018ae7e2a416d98f71f18596d95c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c684695bb6494fd19b8d9b58365ea757"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# 3. Wrap the model for smolagents\n# We use TransformersModel to keep everything local/offline on Kaggle\nsmol_model = TransformersModel(\n    model_id=model_id,\n    tokenizer=tokenizer,\n    max_new_tokens=2048 # Math problems need space to \"think\"\n)\nsmol_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:21:30.688854Z","iopub.execute_input":"2026-01-11T09:21:30.689138Z","iopub.status.idle":"2026-01-11T09:24:00.119179Z","shell.execute_reply.started":"2026-01-11T09:21:30.689103Z","shell.execute_reply":"2026-01-11T09:24:00.117937Z"}},"outputs":[{"name":"stderr","text":"2026-01-11 09:21:32.822558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768123292.985294     133 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768123293.033366     133 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768123293.417950     133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768123293.417972     133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768123293.417975     133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768123293.417977     133 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/680 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ab2d40ab6fa4f418172e708405d67ee"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"468ecd2dc2764de4bf888c742dde6275"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da9fe40ae04497a9855ef95196a3171"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-000002.safetensors:   0%|          | 0.00/6.62G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9686b2c0196466ba9102223fc821a5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-000002.safetensors:   0%|          | 0.00/8.61G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49e277dee7934ad3b11527399121e0be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23fc2fe8f4c84ce8a4ebca842b889cd6"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/smolagents/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_id, device_map, torch_dtype, trust_remote_code, model_kwargs, max_new_tokens, max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             self.model = AutoModelForImageTextToText.from_pretrained(\n\u001b[0m\u001b[1;32m    914\u001b[0m                 \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n\u001b[0;32m--> 607\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.qwen2.configuration_qwen2.Qwen2Config'> for this kind of AutoModel: AutoModelForImageTextToText.\nModel type should be one of AriaConfig, AyaVisionConfig, BlipConfig, Blip2Config, ChameleonConfig, Cohere2VisionConfig, DeepseekVLConfig, DeepseekVLHybridConfig, Emu3Config, EvollaConfig, Florence2Config, FuyuConfig, Gemma3Config, Gemma3nConfig, GitConfig, Glm4vConfig, Glm4vMoeConfig, GotOcr2Config, IdeficsConfig, Idefics2Config, Idefics3Config, InstructBlipConfig, InternVLConfig, JanusConfig, Kosmos2Config, Kosmos2_5Config, Lfm2VlConfig, Llama4Config, LlavaConfig, LlavaNextConfig, LlavaNextVideoConfig, LlavaOnevisionConfig, Mistral3Config, MllamaConfig, Ovis2Config, PaliGemmaConfig, PerceptionLMConfig, Pix2StructConfig, PixtralVisionConfig, Qwen2_5_VLConfig, Qwen2VLConfig, Qwen3VLConfig, Qwen3VLMoeConfig, ShieldGemma2Config, SmolVLMConfig, UdopConfig, VipLlavaConfig, VisionEncoderDecoderConfig.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_133/1111516015.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3. Wrap the model for smolagents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# We use TransformersModel to keep everything local/offline on Kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m smol_model = TransformersModel(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/smolagents/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_id, device_map, torch_dtype, trust_remote_code, model_kwargs, max_new_tokens, max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Unrecognized configuration class\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 self.model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m    927\u001b[0m                     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5046\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5047\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5048\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5049\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5050\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5468\u001b[0;31m                 \u001b[0m_error_msgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisk_offload_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_shard_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5469\u001b[0m                 \u001b[0merror_msgs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_error_msgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload_shard_file\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;31m# Skip it with fsdp on ranks other than 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_quantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         disk_offload_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, hf_quantizer, keep_in_fp32_regex, device_mesh)\u001b[0m\n\u001b[1;32m    768\u001b[0m                     \u001b[0mparam_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                 \u001b[0m_load_parameter_into_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 86.19 MiB is free. Process 6869 has 14.65 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 3.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 86.19 MiB is free. Process 6869 has 14.65 GiB memory in use. Of the allocated memory 14.55 GiB is allocated by PyTorch, and 3.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":14},{"cell_type":"markdown","source":"### 4. Create the Agent\nCodeAgent is the standard for TIR—it will write and run Python code to solve math.","metadata":{}},{"cell_type":"code","source":"agent = CodeAgent(\n    tools=[], # Python Interpreter is the default internal tool\n    model=smol_model,\n    add_base_tools=True, # Adds tools like DuckDuckGo search (if internet is on)\n    max_steps=5 # Limits the agent to 5 \"Think -> Code -> Result\" loops per problem\n)\nprint(\"--- Agent Initialized ---\")\n\nagent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:24:00.120092Z","iopub.status.idle":"2026-01-11T09:24:00.120526Z","shell.execute_reply.started":"2026-01-11T09:24:00.120265Z","shell.execute_reply":"2026-01-11T09:24:00.120294Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. Example Usage","metadata":{}},{"cell_type":"code","source":"# Example usage\nproblem = \"Find the integration of x*e^x from 0 to 1.\"\nprint(f\"\\nSolving: {problem}\")\n\ntry:\n    response = agent.run(problem)\n    print(f\"\\n[Final Answer]: {response}\")\nexcept Exception as e:\n    print(f\"\\n[Error]: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T09:24:00.122388Z","iopub.status.idle":"2026-01-11T09:24:00.122890Z","shell.execute_reply.started":"2026-01-11T09:24:00.122654Z","shell.execute_reply":"2026-01-11T09:24:00.122683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}